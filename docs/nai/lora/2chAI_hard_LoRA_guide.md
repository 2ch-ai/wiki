# Гайд по LoRA
-> by anons <-
-> последнее обновление: 11.10.2023 <-
***
[TOC2]
## Что это

[LoRA (Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning)](https://github.com/cloneofsimo/lora), согласно официальному репозиторию — метод дообучения Stable Diffusion чекпоинтов, который имеет следующие особенности:

- вдвое быстрее чем метод DreamBooth;
- маленький размер выходного файла;
- результаты иногда лучше, чем у традиционного файн-тьюнинга.

Требования для обучения: видеокарта Nvidia, не меньше 8Гб видеопамяти.
***
## Использование

На данный момент есть три способа использования сети LoRA:
1. Использовать нативную поддержку A1111-WebUI
2. Использовать расширение sd-additional-networks
3. Замерджить вместе с SD чекпоинтом

#### Cпособ 1 – использование в промпте WebUI
!!! note По состоянию на 03.10.2023 этот способ является приоритетным для использования, так как поддерживает все дополнительные алгоритмы LyCORIS из коробки.

По умолчанию файлы сетей хранятся в папке *stable-diffusion-webui\models\lora\\*. Туда и нужно скидывать новые скачанные лоры перед использованием.
	
1. В меню генераций нажать **Lora** найти и выбрать интересующую сеть | 2. LoRA появится в промте (отредактируйте значение после ```:``` для изменения весов unet и te при необходимости)
------ | ------
![](https://files.catbox.moe/tlutq9.jpg) | ![](https://files.catbox.moe/klxs6r.png)

#### Cпособ 2 – расширение sd-additional-networks
!!! note По состоянию на 03.10.2023 этот способ считается устаревшим, имеет меньшую скорость в инференс тайме, отличающиеся результаты генераций и не поддерживает алгоритмы вмешивающиеся в размерности матриц, по типу LoKR, LoHA, IA3. Имеется поддержка лишь классической LoRA и алгоритма LoCon.
Установить [расширение от kohya-ss](https://github.com/kohya-ss/sd-webui-additional-networks) для A1111-WebUI.
По умолчанию с этим расширением на наличие файлов сетей сканируется папка *stable-diffusion-webui\extensions\sd-webui-additional-networks\models\lora\\*, но можно добавлять и дополнительные директории для сканирования на наличие лор через **Settings** > **Additional networks** > **Extra paths to scan for LoRA models, comma-separated.**:
-> [![](https://files.catbox.moe/hdm2ks.png)](https://files.catbox.moe/hdm2ks.png) <-
Пользоваться просто:
1. Открыть новую панель | 2. Включить, выбрать модель, настроить веса по вкусу
------ | ------
![](https://i.imgur.com/GvJhlWg.png) | ![](https://i.imgur.com/Ur9iFWk.png)

#### Cпособ 3 – мердж с моделью

!!!danger Этот способ добавляет лору в модель навсегда, а не просто накладывает дополнительные веса в инференс тайме. Делать так стоит лишь в случае, когда вы собираетесь постоянно использовать такую модель или просто хотите создать какой нибудь новый микс чекпоинта.

Для этого лучше всего будет воспользоваться отдельной [тулзой](https://github.com/bmaltais/kohya_ss). Ставим по [инструкции](https://github.com/bmaltais/kohya_ss#windows), и запускаем с помощью **gui.bat**.
Дальше нужно проследовать по вкладкам, как на скрине ниже и выбрать желаемые чекпоинт, лору/лико и путь с названием для новой модели, после нажать Merge model. Merge ratio это сила лоры с которой она будет примерджена.
![](https://files.catbox.moe/8440um.png)

После этого стоит проверить работоспособность мерджа. Сначала сгенерировать картинку с моделью без мерджа и лорой в промпте, а после просто с моделью в которую была примерджена лора, без неё в промпте. Картинки должны быть почти одинаковыми.

***

!!!note Перед тем, как продолжать дальше нужно поставить [CUDA-toolkit](https://developer.nvidia.com/cuda-11-6-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11) и [Python 3.10.X](https://www.python.org/ftp/python/3.10.6/python-3.10.6-amd64.exe).

## Подготовка датасета

#### Общие советы

!!! info Совет №1
    Датасет это основа успешной тренировки. То насколько чисто обработаны картинки в нём влияет на полученную лору больше всего. Все ошметки чужих конечностей, непонятные объекты на картинке, подписи художников, ссылки – все, что вы **не** хотите видеть в генерациях, лучше обрезать или замазать в фотошопе. Разрешение картинок не должно быть ниже, чем то с которым вы будете тренировать. Примерное необходимое количество картинок, под которые не нужно будет крутить дефолтные параметры это:
	- 50-100 для персонажа
	- 75-150 для стиля
	Цифры приблизительны и зависят от каждого конкретного датасета, а так же основываются на опыте автора. Если собрать мало картинок, сеть будет более склонна к перетрену, так и наоборот, если собрать слишком много, на том же лр сеть придётся тренить намного дольше.
!!! info Совет №2
	Теггинг датасета не менее важен, если правильно подобрать теги, которые уже в себе содержат инфу от предыдущих тренировок, это сильно упростит и ускорит задачу. Если тренируете на основе аниме моделей (NAI, AnythingV3), описание делать строго в стиле Danbooru/Gelbooru тэгов. Например, *1girl, short hair, green eyes, black hair, school uniform...*, это как раз пример тех самых тегов, которые уже тренировались в датасете NAI.
	Если тренируете на основе SD 1.x/2.x, в описаниях пишите что вы видите на изображении. Например, если изображение – рисунок бородатого рыбака за работой, пишите *pencil art of a man fishing, beard*; если это фото вашего улыбающегося друга в очках и красной рубашке на фоне заката, пишите *photo of friend_name, smiling, wearing glasses, red shirt, sunset in the background*)
!!! info Совет №3
	Если тренируете персонажа/человека, желательно чтобы датасет состоял только из изображений, где он присутствует, алсо рекомендуется придерживаться разных стилей в артах, если это аниме персонаж. И чтобы во всех описаниях было ключевое слово, описывающее этого персонажа/человека. Например, 1.txt: *photo of AndrewFriend, jacket, jeans*; 2.txt: *photo of AndrewFriend, shorts, t-shirt*. Вызывать вы данного человека в промте будете соответственно через тег *AndrewFriend*. Тоже самое работает и для аниме моделей – в этом случае это будет имя персонажа. Например, *shiina mayuri, 1girl, short hair, green eyes* и т.д. Вызов через *shiina mayuri* соответственно. Также, если модель уже изначально немного догадывается о вашем персонаже, которого вы будете тренировать по соответствующему тегу, это ещё больше упростит задачу.
	Если тренируете авторский стиль, как и в предыдущем абзаце желательно чтобы датасет состоял только из изображений, нарисованных данным автором и не меняющихся в стиле, у некоторых авторов есть тенденция менять его со временем. Также рекомендуется, в случае со стилями, тренировать с **NAI** чекпоинта (старый хеш - 925997e9, новый хеш - 89d59c3dde). Для тех, кто забыл [где взять этот чекпоинт](magnet:?xt=urn:btih:5bde442da86265b670a3e5ea3163afad2c6f8ecc&dn=novelaileak&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2F9.rarbg.com%3A2810%2Fannounce&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A6969%2Fannounce&tr=http%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Fopentracker.i2p.rocks%3A6969%2Fannounce). Тегать можно так же как и с персонажем, но отдельный тег заводить не обязательно. Пример описания: *mountains, night, moon, snowy peaks, stars* и т.д.
!!! info Совет №4
    Для ускорения ручного тегирования можно использовать мокрописьки ([1](https://github.com/hydrusnetwork/hydrus), [2](https://github.com/arenatemp/sd-tagging-helper), [3](https://github.com/starik222/BooruDatasetTagManager)).
	Либо использовать расширения ([1](https://github.com/picobyte/stable-diffusion-webui-wd14-tagger), [2](https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor), [3](https://github.com/SesuMoe/sd-tagger-webui)) для A1111-webui.
	Для скачивания изображений с различных booru-досок вместе с тегами можно использовать [Grabber](https://github.com/Bionus/imgbrd-grabber/releases) с [такими настройками](https://files.catbox.moe/e29fq5.png) (скопируйте и вставьте: ```%character:unsafe,separator=^,^ %, %general:unsafe,separator=^,^ %```).
	Простым способом для тренировки стиля/аниме персонажа будет либо [протегать всё](https://files.catbox.moe/51gecu.png) вот этим [расширением](https://github.com/picobyte/stable-diffusion-webui-wd14-tagger), либо скачать готовые теги с пикчами данбору/гелбуру с помощью граббера с настройками выше. Достаточно просто, после ввода соответствующих тегов, нажать Get all, после перейти на вкладку Downloads и запустить загрузку, после чего приступить к сортировке картинок, вот кстати полезный [скрипт](https://files.catbox.moe/5fii8o.py), чтобы почистить тхтшники после удаления пикч, на всякий случай.
!!! info Совет №5
	Общее рекомендуемое предельное количество шагов для тренировки можно посмотреть [тут](#-max_train_steps-max_train_steps).
	
***

#### Структура датасета

Датасету необходима определённая структура папок:

-> ![Пример структуры папок](https://i.imgur.com/hJsmBzK.png) <-
-> Пример структуры папок <-

Где **n** – количество *повторений* данного концепта; **conceptA**, **conceptB** – имена концептов. Имя концепта может быть любое, оно нигде не используется (кроме особого случая, см. *Важные замечания*), это скорее заметка для вас, что в этой папке находится. Между количеством повторений и именем концепта обязательно наличие нижнего подчеркивания. Внутри каждой папки концепта должны присутствовать изображения вместе с файлами описания в формате \*.txt, их имена должны совпадать. Внутри текстовых файлов должно быть, собственно, описание. Папок концептов может быть сколько угодно, но хотя бы одна должна присутствовать. **Обрезать изображения необязательно**.
[Пример датасета для тренировки стиля](https://mega.nz/folder/KiJ23KJL#1ovvD60VA_eJOMhJ6uLXrg)
!!! warning Важные замечания
	Если у файла *image.png* не будет соответствующего *image.txt*, скрипт [выдаст ему описание в виде имени концепта](https://github.com/kohya-ss/sd-scripts/blob/main/library/train_util.py#L513). Например, если папка концепта называется *6_photo*, будет считаться, что у файла *image.png* описание *photo*.
	Поддерживаемые форматы изображений: *\*.png, \*.jpg, \*.jpeg, \*.webp, \*.bmp*. 

**Повторения** нужны чтобы контроллировать количество времени тренируемых концептов относительно всего датастета. В случае с одной папкой достаточно будет просто подогнать количество повторений под рекомендуемые, от 200 до 600 итераций на эпоху. В случае с несколькими лучше удерживать баланс тренируемых частей, выставив повторения соответствующим образом. Например, у вас есть папка *1_nekochan* с 76 изображениями внутри и папка *6_maid* с 16 изображениями внутри. Суммарно это даст 172 (1 \* 76 + 6 \* 16) итераций на эпоху из этих папок, и нейронная сеть будет обучаться по времени равномерно нескольким концептам.

!!! info Регуляризационные изображения для данного способа тренировки не требуются и лучше обойтись без них.

***

## Тренировка

По состоянию на 03.10.2023 существует как минимум три GUI-обёртки для [sd-scripts](https://github.com/kohya-ss/sd-scripts), основного репозитория скриптов для тренировки:
[1)](https://github.com/derrian-distro/LoRA_Easy_Training_Scripts) Автоматически поставит все нужные зависимости и настроит окружение.
[2)](https://github.com/bmaltais/kohya_ss) Тоже избавит от нужды пердолиться с установкой, но работает как и WebUI, через браузер.
[3)](https://github.com/anon-1337/LoRA-train-GUI) Требует отдельно настроенного venv с sd-scripts. Был создан оригинальным автором этого гайда и мало чем отличается от тренировки с помощью скрипта, поэтому ручная установка, описанная в нём, будет актуальна и здесь.

#### Суть
Суть любой тренировки лоры заключается в попадании в свитспот сразу двух составных частей Stable diffusion модели, Unet и TE.
-> ![](https://files.catbox.moe/s6tp80.jpg) <-
Правильный подбор параметров как раз поможет как в попадании сразу в обе составляющих, в виде юнета и те, так и в растягивании этого окна свитспота, посредством грамотного замедления тренировки.

#### Easy way

Сначала будет показан простой путь для тренировок, для тех кто не хочет пердолиться со скриптами и прочими проблемами.
1) Поставить [gui для тренировки](https://github.com/derrian-distro/LoRA_Easy_Training_Scripts).
На вопросы отвечаем так:
Which version of torch do you want to install?? 
– **2.0.1**
Do you want to install the triton built for torch 2?
– **n**
Do you want to install the optional cudnn patch for faster training on high end 30X0 and 40X0 cards?
– **y**
2) Запустить гуй с помощью **run.bat** в директории установки.
3) Далее всё будет зависеть от видеокарты, на которой будет происходить тренировка. Вот примеры конфигов для [8](https://files.catbox.moe/vo0dbu.toml), [12](https://files.catbox.moe/2vhu6r.toml) и [24](https://files.catbox.moe/9de21x.toml) гигабайтных видеокарт.
==Внимание, в параметрах **Training precision** и **Saving precision** конфигов выставлена **BF16** точность, если ваша GPU ниже линейки RTX3000, настоятельно советую сменить эти параметры на **FP16** во избежании дальнейших проблем.== 
После их импортирования, в них нужно будет подкорректировать пути к моделям/логам следующим образом:

- **Base model** - здесь нужно указать чекпоинт с которого будет происходить тренировка, например *C:/ai/nai-nsfw.ckpt*
- **В Saving args > Output folder** - нужно указывать на директорию в которую будут сохраняться новоиспечённые лоры, например *C:/ai/my-lora-dir*.
- **В Saving args > Output name** - нужно указывать имя будущей лоры, например *my-best-waifu-lora*.
- **В Logging args > Log output directory** - следует указывать директорию для логов тренировки, например *C:/ai/my-lora-logs*.
- **В Logging args > Prefix for log folders** - стоит указать префикс логов, который будет добавляться в начало названий их директорий, например *my-best-waifu-logs-*.
- После стоит перейти на вкладку **Subset args** и нажать на кнопку **Add all subfolders from folder** и указать на путь к датасету, который представляет из себя папку, в которой содержатся директории вида 2_my-waifu-pics, например *C:/sikret-folder/fap-pictures-with-my-waifu*. Здесь так же стоит поставить галочки *shuffle captions* на частях датасета, где это необходимо.

Далее, как все пути расставлены верно, нужно запустить тренировку, нажав на кнопку **Start training**.
4) Как тренировка завершится в папке, которая указана в строке Output Folder, раздела Saving args, появятся эпохи натренированных лор. Далее внутри каталога вебуи **stable-diffusion-webui\models\Lora** стоит создать новую директорию и закинуть свежесозданные сети туда и запустить вебуи.
5) Протестировать новые лоры можно разными способами, чем больше тестов вы прогоните, тем лучше будуте знать о плюсах и минусах получившихся нетворков, так же тесты помогут определить самую сочную эпоху.
- Первый пример тестов грид с весами и лорами: Для построения XYZ плота потребуется установка [адднетов](https://github.com/kohya-ss/sd-webui-additional-networks). 
==Внимание, в настройках Additinal networks нужно указать дополнительный путь для сканирования лор, чтобы они подхватывались из дефолтной директории вебуи.==
-> ![](https://files.catbox.moe/hdm2ks.png) <-
Чтобы быстро выставить желаемые сети в грид, нужно сперва выбрать одну из свежесозданных сетей в меню Additional networks, заодно не забыв нажать кнопку Enable. Затем внизу страницы выбрать скрипт X/Y/Z plot в **X type** выбрать **AddNet Model 1** и нажать на кнопку 📒 для заполнения всеми новыми лорами из директории, в **Y type** стоит выбрать **AddNet Weight 1** и выставить диапазон весов лор, например **0.7-1.5 \[5\]** даст значения 0.7, 0.9, 1.1, 1.3, 1.5. Скриншот ниже показывает, как должно получиться в итоге для построения грида.
    Взглянув на грид можно примерно понять на какой эпохе сеть натренилась достаточно, если это впринципе произошло и сеть не получилась недотрененной. Для совсем же ленивых, можно будет просто взять последний чекпоинт, полученный после тренировки и попробовать его в деле. Пережар текстового энкодера будет выражаться в невозможности запромптить что-то кроме того, что было в тегах датасета, пережар юнета всякого рода артефактами, сильным перерисовыванием изображения в инпеинте, и2и или хайрезе, а также разными нежелательными объектами даже на лоурезных пикчах, по типу дополнительных рук, не в тему летающей где то рядом херни от фона. Недожар же можно будет понять по слабому возпроизведению тренируемого концепта/стиля. Подробнее про примерные хорошие базовые значения параметров, можно посмотреть в разделе [параметров тренировки](#параметры-тренировки).
1. Настройка адднетов и скрипта для построения грида | 2. Грид с примером, где последняя эпоха вышла хорошей, но можно было тренить и дальше, исходя из того, что на 1.5 силе всё ещё нету сильных поломок картинки
------ | ------
[![Настройка адднетов](https://files.catbox.moe/4fdsde.png)](https://files.catbox.moe/4fdsde.png) | [![Грид с небольшим андерфитом](https://files.catbox.moe/xe7f96.jpg)](https://files.catbox.moe/xe7f96.jpg)

- Однако такой способ может оказаться плох из-за черрипикинга удачно или неудачно попавшегося сида, важно так же взглянуть на грид с несколькими сидами, дабы иметь представление о перформансе нетворков в целом, для этого достаточно **Y type** заменить на **Seed** и вписать туда значение **-1--1 \[8\]**. Так же было бы неплохо использовать в таком случае вайлдкард на фоны прямо в промпте, чтобы косвенно оценить влияние на них свежесозданных лор.

-> [![](https://files.catbox.moe/syko7z.jpg)](https://files.catbox.moe/syko7z.jpg) <-


6) Когда годная эпоха уже найдена, можно сделать ещё одну вещь, снизить ранг модели, это едва ли ухудшит качество генерируемых пикч, но поможет сохранить место, особенно если таких сетей уже скопилось довольно весомое количество и каждая весит по 150мб.
	Сделать это можно [с помощью anon1337-gui](https://files.catbox.moe/ghrks9.png), либо же вручную, просто найдите папку с установленными sd-scripts, будь то ручная установка или установка гуя, далее введите команды в консоль павершелла, открытую в этой папке:
	```powershell
	.\venv\Scripts\activate.ps1
	python .\networks\resize_lora.py --save_precision bf16 --new_rank 32 --save_to "A:\tmp\derrian-tmp\output-test-8gb\40hara-test-000015-32rank.safetensors" --model "A:\tmp\derrian-tmp\output-test-8gb\40hara-test-000015.safetensors" --device cuda --dynamic_method sv_fro --dynamic_param 0.9
    ```
	*Надёжным* рангом для ресайза можно считать не ниже 32. Ранги с 8 по 24 могут помочь сохранить в хлам пережаренную сеть, если ресайзить её в них, там уже идёт потеря значительного количества информации из нетворка. [На этом гриде](https://files.catbox.moe/dq8loo.png) c немного недотрененной сетью прекрасно видно, какое может быть влияние ресайза, тем более в 16 ранг, особенно если сеть недотренена, на второй строке с сидом.

#### Ручная установка для тренировки с помощью скрипта, либо LoRA-train-GUI

1. Клонировать репозиторий в любую папку: ```git clone https://github.com/kohya-ss/sd-scripts.git```, либо же просто в ручную скачать его [отсюда](https://github.com/kohya-ss/sd-scripts)
2. Открыть PowerShell и поочерёдно выполнить следующие команды, либо же запустить [скрипт](https://files.catbox.moe/ungey0.ps1) внутри свежей папки с sd-scripts:
```powershell
Set-Location <путь к папке sd-scripts> # Переходим в каталог репозитория

python -m venv venv # Создаём виртуальное окружение
.\venv\Scripts\activate # Активируем его

# Устанавливаем torch и torchvision, xformers, а также необходимые зависимости
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install --upgrade -r requirements.txt
pip install xformers==0.0.21
pip install dadaptation==3.1 lycoris_lora
pip install bitsandbytes==0.35.0

# Копируем скомпилированные под Windows CUDA библиотеки, вручную или командами. На Linux этот шаг не обязателен
cp .\bitsandbytes_windows\*.dll .\venv\Lib\site-packages\bitsandbytes\
cp .\bitsandbytes_windows\cextension.py .\venv\Lib\site-packages\bitsandbytes\cextension.py
cp .\bitsandbytes_windows\main.py .\venv\Lib\site-packages\bitsandbytes\cuda_setup\main.py

accelerate config
```
3. После последней команды терминал начнёт задавать вопросы, выбрать следующее:
In which compute environment are you running? 
– **This machine**
Which type of machine are you using?
– **No distributed training**
Do you want to run your training on CPU only (even if a GPU is available)?
– **NO**
Do you wish to optimize your script with torch dynamo?
– **NO**
Do you want to use DeepSpeed?
– **NO**
What GPU(s) (by id) should be used for training on this machine as a comma-seperated list?
–  **0** или **all**
Do you wish to use FP16 or BF16 (mixed precision)?
– **fp16** или **bf16**
!!! info BF16 > FP16
    Если железо поддерживает BF16 (rtx 3000 и выше), лучше выбрать его. Почему, можно почитать подробнее в описании [параметров](#параметры-тренировки).
!!! info Если PowerShell сыпет ошибками при нажатии на стрелочки
	Выключить NumLock на клавиатуре, выбирать варианты при помощи кнопок 8 и 2 на нампаде. [Если нампада нет](https://i.imgur.com/ARViwie.png).

4. Скачать [скрипт](https://files.catbox.moe/3k6pbx.ps1)
!!! info PowerShell
	Данный скрипт предназначен для PowerShell, но это не значит что он доступен только пользователям последних версий Windows. Не все знают, но [PowerShell доступен для всех версий Windows начиная с XP, на Linux, а также на macOS](https://github.com/PowerShell/PowerShell/releases).

5. Редактирование скрипта
Открыть скрипт любым текстовым редактором и изменить переменные вверху файла под свои нужды. Опираясь на информацию, которую можно прочитать в разделе [параметров тренировки](#параметры-тренировки). Как минимум стоит указать правильные пути к датасету, моделям и папке с sd-scripts.

6. Запуск скрипта
!!! note Если не открывается по двойному щелчку
	В папке со скриптом ПКМ в свободном месте \-> "Открыть в Терминале" \-> ввести **.\название_скрипта.ps1** и нажать Enter.

***

## Параметры тренировки

### --learning_rate ($learning_rate в скрипте)
Скорость обучения. Основной рычаг управления обучением, если поставить слишком большое число, сеть будет учиться из под палки и результат будет соответствующе пережарен, если поставить маленькое число, сеть будет учиться слишком лениво и долго, что совсем не подходит для такого быстрого метода обучения как лоры. Этот параметр целиком и полностью зависит от других параметров а так же количества картинок в датасете:

- Для AdamW8bit оптимайзера - хорошим стоковым значением является **1e-4 (0.0001)** с network_dim=network_alpha=64-128.
- Для адаптивных оптимайзеров, таких как DAdaptation, Prodigy значение этого параметра необходимо указывать в диапазоне на несколько порядков выше, 0.5-2.0, но хорошим дефолтом можно считать именно значение **1.0**. Данные оптимайзеры *by design* созданы так, чтобы упразднить этот параметр, с ними он не имеет такой силы, как с классическими и управлять скоростью обучения лучше с помощью параметров самого оптимайзера, либо другими параметрами, о влиянии которых можно прочитать далее. У адаптивных оптимайзеров также нету разделения этого параметра на unet_lr и text_encoder_lr, что немного усложняет задачу не поджечь те в процессе.

Наглядные примеры андерфита (недотрена, недожарки) и оверфита (перетрена, пережарки). Для этих примеров были выключены все улучшалки, safety measures и локон, а так же уменьшен и увеличен лр в 10 раз соответственно.

1. Underfit | 2. Overfit
------ | ------
[![Underfit](https://files.catbox.moe/c9ya4r.png)](https://files.catbox.moe/c9ya4r.png) | [![Overfit](https://files.catbox.moe/ybaxj4.png)](https://files.catbox.moe/ybaxj4.png)

В первом случае видно, что картинка слабо меняется в стиле по сравнению с дефолтной, без лоры. Во втором наглядная демонстрация взрыва юнета и те при оверфите, где очень много левой херни на картинке, а также повылезали и горничная и кошка, хотя они находятся в другой части датасета и вызываются абсолютно другими тегами, о плавности тренировки тут не идёт даже и речи.
Данный параметр можно разделить на два раздельных лернинг рейта для разных частей сд, используя классические оптимайзеры.

#### --unet_lr ($unet_lr в скрипте)
Скорость обучения UNet. UNet это такая часть в сд, которая отвечает за пошаговое преобразование шума в картинки, можно грубо себе это представить как графическую составляющую, которая и будет запоминать новую информацию. Именно для этого параметра подходят рекомендации, расписанные в learning_rate.

#### --text_encoder_lr ($text_encoder_lr в скрипте)
Скорость обучения TE - text encoder. Эта часть сд, которая отвечает за преобразование того, что пишет пользователь в промпте в математические значения, для дальнейшего гайданса юнета во что ему преобразовывать шум. Не такая крупная, и судя по [вот этой информации](https://github.com/cloneofsimo/lora/discussions/37) количество тренируемых параметров у неё почти втрое меньше на одинаковом ранге. Поэтому хорошим значением может считаться unet_lr/2-3, то есть **3.3e-5 - 5e-5**, если лр юнета равен 1e-4. 
Раздельные скорости обучения для unet_lr и этого параметра на адаптивных оптимайзерах невозможны, поэтому в случае с ними значение нужно ставить таким же как и learning_rate.

#### --lr_warmup_steps ($lr_warmup_ratio в скрипте)
Шаги разогрева планировщика лр. Скрипт настроен для высчитывания этих шагов в процентном соотношении. $lr_warmup_ratio - процент шагов начиная с первого, в течении которых скорость обучения линейно увеличивается от 0 до значения learning_rate. Полезен с низкими значениями **0.05-0.1**, помогает плавно начать тренировку с маленького лр и [не перенасытить сеть слишком рано](https://stackoverflow.com/a/55942518).

### --optimizer_type ($optimizer_t в скрипте)
Тип оптимайзера, ещё один из важнейших параметров влияющих на то, как придётся подстраивать остальные. Их существует огромное количество, в том числе и кастомных, вот только из хелпы сд-скриптс: *AdamW, AdamW8bit, Lion8bit, Lion, SGDNesterov, SGDNesterov8bit, DAdaptation(DAdaptAdamPreprint), DAdaptAdaGrad, DAdaptAdam, DAdaptAdan, DAdaptAdanIP, DAdaptLion, DAdaptSGD, AdaFactor*. Разные их версии отличаются разными необходимыми параметрами, а также разным потреблением ресурсов гпу. Здесь же будет написано лишь про несколько из них, самых полезных:
- AdamW8bit. Король, которого сложно переплюнуть, практически все существующие гайды по тренингу лор расписывают именнно его параметры и как подстраивать всё остальное под него. Имеет маленькое потребление VRAM и не 8битную версию, которая ест чуть больше, но не прибавляет особо в качестве. Просто работает и считается дефолтом, остальные будут сравниваться именно с ним. Не нуждается в особых параметрах, но если очень хочется, то вот такие подставляются к нему в derrian-gui ```"weight_decay=0.01" "betas=0.9,0.999"```. Хорошо подходит для стилей.
- DAdaptAdam. Адам без нужды регулировать лр. Имеет более низкую скорость итераций тренировки и повышенное потребление VRAM. Нуждается в аргументах, ```"decouple=True" "weight_decay=0.01" "betas=0.9,0.99"``` иначе ничего не будет работать. С помощью **weight_decay** можно регулировать скорость его обучения, чем выше поставить число, тем она станет ниже. На момент написания этого гайда, этот оптимайзер является самым удобным из всех адаптивных, в прошлом он претерпел ряд изменений и самые удачные версии это 3.1 и 1.5, в которой кстати ещё была возможность разделения лров, но я не уверен что она работала корректно. В версии 1.5, кстати он назывался и вызывался в скриптах просто как DAdaptation. У этого оптимайзера есть некоторые проблемы с тренировкой стилей, но в целом он хорош и использовать его можно с таким же успехом, как и обычный адам. Он так же является **недетерминированным**, что усложняет сравнения тренировок с другими параметрами на нём. [Есть мнение](https://github.com/kohya-ss/sd-scripts/issues/181#issuecomment-1433193143) что с низким значением network_alpha динамический лр с этим оптимайзером может быть подобран слишком большим.
- Prodigy. Прололжение DAdaptAdam, также является адаптивным оптимайзером, не самое удачное решение, трудноконтроллируемый, нуждается в тонкой настройке своих параметров, иначе сожжёт всё быстрее, чем взглянуть на тензорборд ```"decouple=True" "weight_decay=0.01" "d_coef=2" "use_bias_correction=True" "safeguard_warmup=True"```. Всё что актуально для DAdaptAdam, актуально и для него. Больше склонен сжарить те, нежели его предок. d_coef - очень важный параметр, если поставить его слишком низким, лр начнёт скакать выше начального посередине тренировки. safeguard_warmup - можно использовать вместе с вармапом, не особо полезно, учитывая что и он и DAdaptAdam имеют свой вармап.
- Lion. По заверениям разработчиков, замена AdamW, на деле выдаёт чуть хуже качество, с параметрами, рекомендуемыми самими разработчиками. Что точно известно, так это то что он с другими одинаково равными параметрами требует лр в 10-15 раз ниже адамовского, то есть 1e-5 --- 2e-6. Вообщем оптимайзер для экспериментов. Имеет 8битную версию, но для неё нужны более свежие библиотеки bitsandbytes.

#### --optimizer_args ($optimizer_args в скрипте)
Собственно те самые аргументы для оптимайзера: ```"decouple=True" "weight_decay=0.01" "betas=0.9,0.99"```

#### --min_snr_gamma ($min_snr_gamma)
Прямой импрувмент [конвергенции (сходимости с датасетом) тренировки](https://arxiv.org/pdf/2303.09556.pdf), что можно увидеть на графиках тензорборда:

1. Меньшие расхождения значений loss'а | 2. Улучшенная общая сходимость с датасетом
------ | ------
[![Меньшие расхождения значений loss'а](https://files.catbox.moe/xz11cb.png)](https://files.catbox.moe/xz11cb.png) | [![Улучшенная общая сходимость с датасетом](https://files.catbox.moe/l6ryyx.png)](https://files.catbox.moe/l6ryyx.png)

Добавляет плавности к тренировке, видно что нету такого сильного шатания loss'а при добавлении этого параметра. Можно считать это одной из safety measures, чем меньше число, тем сильнее будет эффект, рекомендуемое значение - **5**. В какой то степени этот параметр поможет с маленьким батч сайзом и неоднородностями датасета, выравнивая их.

#### --scale_weight_norms ($scale_weight_normals)
Ещё одна safety measure, которую предлагается [использовать в связке с network_dropout](https://github.com/kohya-ss/sd-scripts/pull/545). Скейлит ключи, которые имеют слишком большие значения для весов в них. В консоли выводится значение подсчётов `Average key norm=tensor(0.5194, device='cuda:0')` ключей, и количество отскейленных `Keys Scaled=0`. Может сигнализировать о пережарке юнета, если ключи начинают часто скейлится и счётчик Keys scaled растёт, так же есть мнение что этот параметр придаст лоре большую флексибилити для комбинации с другими в инференс тайме. Что заметил лично я, так это то, что использование этого параметра со значением 0.9-1.0 в одиночку, без дропаута, добавляет ещё больше плавности к тренировке. Лучше не переусердствовать со значением, иначе сеть [ничему не научится](https://files.catbox.moe/pk8qgo.png).

### --lr_scheduler ($scheduler в скрипте)
Планировщик кривой лернинг рейта. Дефолтные со спадающим лром не сильно друг от друга отличаются, но и тут есть пара нюансов. Для долгих тренировок стилей лучше всего подходят разнообразные косинусы с рестартами/подогревами. Константный шедулер рекомендуется юзать вместе с адаптивными оптимайзерами, а вот обычный адам его плохо переваривает, ему нужен постоянно спадающий лр.
Дефолтные шедулеры поставляемые с sd-scripts: *linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup, adafactor*.
- [constant](https://www.kaggle.com/code/rhtsingh/guide-to-huggingface-schedulers-differential-lrs#Constant-Schedule): скорость обучения не изменяется во времени с начала и до конца обучения. Единственный планировщик, который не использует переменную *lr_warmup_ratio*. 

Все остальные планировщики используют переменную *lr_warmup_ratio* и имеют следующие формулировки:
После периода разогрева, длящегося *lr_warmup_ratio%* шагов, в течение которого скорость обучения линейно увеличивается между 0 и *learning_rate*:
- [linear](https://www.kaggle.com/code/rhtsingh/guide-to-huggingface-schedulers-differential-lrs#Linear-Schedule-with-Warmup): скорость обучения линейно уменьшается от значения *learning_rate* до 0.
- [cosine](https://www.kaggle.com/code/rhtsingh/guide-to-huggingface-schedulers-differential-lrs#Cosine-with-Warmup): скорость обучения уменьшается вслед за значением косинусной функции между *learning_rate* и 0.
- [cosine_with_restarts](https://www.kaggle.com/code/rhtsingh/guide-to-huggingface-schedulers-differential-lrs#Cosine-With-Hard-Restarts): скорость обучения уменьшается вслед за значением косинусной функции между *learning_rate* и 0, с несколькими жёсткими перезапусками.
- [polynomial](https://www.kaggle.com/code/rhtsingh/guide-to-huggingface-schedulers-differential-lrs#Polynomial-Decay-with-Warmup): скорость обучения уменьшается как полиномиальный распад со значения *learning_rate* до значения 1e-7.

Вот так они выглядят на графике тензорборда.
1. Constant | 2. Polynomial 0.75 power | 3. Cosine | 4. Linear | 5. Cosine with 4 restarts
------ | ------ | ------ | ------ | ------
[![Constant](https://files.catbox.moe/mtvrvp.png)](https://files.catbox.moe/mtvrvp.png) | [![Polynomial 0.75 power](https://files.catbox.moe/iaoj65.png)](https://files.catbox.moe/iaoj65.png) | [![Cosine](https://files.catbox.moe/peixh8.png)](https://files.catbox.moe/peixh8.png) | [![Linear](https://files.catbox.moe/ycpl4s.png)](https://files.catbox.moe/ycpl4s.png) | [![Cosine with 4 restarts](https://files.catbox.moe/1od21t.png)](https://files.catbox.moe/1od21t.png)

#### --lr_scheduler_num_cycles ($lr_r_num_cycles в скрипте)
Количество рестартов шедулера cosine_with_restarts. Пример применения: ```--lr_scheduler_num_cycles=4``` даст **три** рестарта, самое начало тренировки тоже считается рестартом.

#### --lr_scheduler_power
Сила спада Polynomial шедулера, чем ближе к 0 значение, тем раньше и сильнее начнётся распад.

#### --lr_scheduler_type ($lr_scheduler_type)
Возможность добавить кастомный шедулер, прямо через аргумент. Например ```--lr_scheduler_type=cosine_annealing_warmup.CosineAnnealingWarmupRestarts```

#### --lr_scheduler_args ($lr_scheduler_args)
Аргументы кастомного шедулера. Например ```--lr_scheduler_args "T_0=549" "gamma_min_lr=0.99915" "decay=1" "down_factor=0.5" "warmup_steps=100" "cycle_warmup=50" "init_lr_ground=True"```

#### Рекомендация по кастомному шедулеру для тренировки стилей
Стили с помощью лор тренируются дольше всего и так получилось, что лучшим шедулером для такого дела является cosine_with_restarts, но у него есть один изъян. Моментальное повышение лр за 1 шаг с 0 до значения указанного в learning_rate. Получалось так, что где-то на протяжении одной эпохи бывает слишком маленький лр (ниже 1е-6) чтобы сеть могла чему то научиться, а после резкое повышение, что сказывавается на плавности тренировки. Для решения этой проблемы я предлагаю использовать кастомный шедулер основанный на [шедулере из этого репозитория](https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup.git), объясню как его поставить:

1) Сначала нужно поставить оригинальный шедулер внутри venv папки с сд-скриптс командами:
```powershell
.\venv\Scripts\Activate.ps1
pip install 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'
```
2) Пройти по пути **sd-scripts\venv\Lib\site-packages\cosine_annealing_warmup** и поменять название лежащего там файла с **scheduler.py** на **scheduler.py.bckp**.
3) Скачать [кастомный шедулер](https://files.catbox.moe/z6t4ii.py) в эту папку с названием **scheduler.py**.

Правильный вызов в скрипте этого шедулера показан в параметрах чуть выше. ```T_0``` стоит высчитывать так: высчитать общее количество шагов, которое будет сделано во время тренировки, например 1600 и поделить его на желаемое количество рестартов. Это число, в данном случае 400 и нужно вписывать в ```T_0```, в этот момент будет происходить рестарт с подогревом. С помощью ```gamma_min_lr``` стоит регулировать скорость спада лр, чем ниже число, тем быстрее он будет понижаться.

##### Matplotlib для визуализации не адаптивных шедулеров
Удобно визуализировать работу этого шедулера можно с помощью ещё одного [скрипта с дамми нетворком](https://files.catbox.moe/7gv6rk.py). Достаточно лишь разобраться с импортами вверху него, установив нужные зависимости и положив его рядом с самим шедулером (не обязательно это делать в venv кохи, можно копировать куда нибудь в другое место).
-> ![Визуализация шедулера](https://files.catbox.moe/khmqx2.png) <-

### --network_dim ($network_dim в скрипте)
Размер сети. Параметр определяющий количество тренируемых параметров UNet и TE, чем выше, тем больше параметров будет обновляться на каждом проходе. Является одним из параметров, влияющих на скорость обучения, при низких значениях он её замедляет, но не так значительно как остальные. Так же влияет на размер выходного файла и высчитывается по формуле network_dim x 1,125 при половинной точности (FP16, BF16). Влияет на потребление VRAM во время тренировки, чем меньше значение, тем оно будет ниже. Значения выше 128 избыточны, но достаточно придерживаться значения **64**, поэтому его я и считаю хорошим дефолтом для этого параметра.

#### --network_alpha ($network_alpha в скрипте)
Параметр, [изначально введённый](https://github.com/kohya-ss/sd-webui-additional-networks/issues/49), чтобы бороться с андерфлоувами выходных весов, когда веса близкие к нулю округлялись до последнего и записывались в тензор, работает скалирование через формулу network_alpha/network_dim. Для тех, кто может использовать преимущества BF16 точности этот параметр нужен в первую очередь только для замедления тренировки. Является вторым по силе замедлителем тренировки и плохо влияет на обучение стилей. В случае с FP16 не полностью убирает нулевые значения, а лишь снижает их количество, чем больше соотношение, тем меньше будет нулевых тензоров.
При понижении этого параметра требуется компенсировать скорость обучения повышением лернинг рейта, в случае с не адаптивными оптимайзерами, примерное рекомендуемое значение для значений альфа=1, рамзерность сети=64 - это повышение лр юнета в 10 раз, до 1e-3.
Хорошие значения:
- **От 1/1 до 1/4** от размерности сети - для тренировки стилей.
- **От 1 до 16** при размерности сети равной 64 для тренировки простых персонажей.

#### --mixed_precision ($mixed_precision) и --save_precision ($save_precision)
Выбор этого параметра зависит от имеющейся гпу для тренировки. Если есть RTX3000 и выше, оба значения лучше ставить в BF16. FP16 подойдёт для владельцев других карт, но этот формат имеет слишком мало бит на экспоненту и из-за этого в итоговой лоре может получиться очень много нулевых тензоров. Кстати про это, проверить тензоры модели можно при помощи одного из скриптов в наборе sd-scripts, а именно networks\check_lora_weights.py. Как обычно через venv из папки networks, предварительно положив рядом интересующий нетворк:
```powershell
..\venv\Scripts\Activate.ps1
python .\check_lora_weights.py .\rizento_v1-000018.safetensors > out.txt
```
Открываем этот out.txt, ну например с помощью notepad++ и ищем 0.0\r\n поставив чекбокс search mode в extended нажав на count.

-> ![Пример поиска нулевых тензоров](https://files.catbox.moe/fu9grk.png) <-

У нормально натрененной лоры, на 2 клип скипе должно быть всего навсего 6 найденных значений, если больше, значит были ошибки пресижиона, их кстати можно пофиксить, заресайзив модель, как показано в 6 пункте [easy way](#easy-way), по всей видимости при ресайзе первыми отбрасываются именно нулевые значения.

### --network_module ($network_module)
Определяет основную реализацию алгоритмов скриптов для тренировки, которых всего две, от [кохи](https://github.com/kohya-ss/sd-scripts) и [кохака](https://github.com/KohakuBlueleaf/LyCORIS). Расписывать про преимущества реализаций, основываясь на опыте, я не смогу, так как не тестировал их face to face, ну и со временем они меняются, фиксятся или добавляются баги, появляются новые алгоритмы и тд. Подробнее про правильный вызов с параметрами можно почитать [вот тут](https://seesaawiki.jp/nai_ch/d/Dreambooth-LoRA#content_8_17), Ctrl+F "network_module" на странице.
Имеет несколько принимаемых параметров, но выбирать нужно один:
- **networks.lora** - обычная реализация от кохи, принимающая на вход аргументы без указания алгоритма, но можно указать conv слои, о чём будет рассказано чуть позже.
- **networks.dylora** - реализаций DyLoRA от кохи, из моих тестов, эта реализация тренится медленнее реализации кохака. Также никто не мешает накинуть сюда конволюшена.
- **locon.locon_kohya** - старая реализация локона онли, до того как этот проект перерос в ликорис, которая лежит [здесь](https://pypi.org/project/locon/), *for legacy reasons*.
- **lycoris.kohya** - [реализация](https://pypi.org/project/lycoris-lora/) дополнительных алгоритмов, в том числе и дилоры от кохака, принимает другие параметры.

#### --network_args
Аргументы для network_module. Для каждой из реализаций нужно передавать свои параметры:
- **networks.lora, locon.locon_kohya, networks.dylora** - принимают на вход ```"conv_dim=32" "conv_alpha=32"```
- **lycoris.kohya** - принимает на вход такие же параметры с дополнительным указанием тренируемого алгоритма ```"conv_dim=32" "conv_alpha=32" "algo=locon"```. Возможные алгоритмы: ```full, lora, locon, loha, dylora, lokr, ia3```, подробнее про выбираемый алгоритм можно [почитать тут](https://github.com/KohakuBlueleaf/LyCORIS/blob/document/docs/Guidelines.md) или же [пейпер](https://browse.arxiv.org/pdf/2309.14859.pdf), выбор алгоритма будет влиять на всю последующую тренировку, можно тренировать даже вплоть до полноценного чекпоинта. Так же может принимать параметр тренировки слоёв нормализации ```"train_norm=True"```, тренируемый [пресет](https://github.com/KohakuBlueleaf/LyCORIS/blob/e4259b870d3354a9615a96be61cb5d07455c58ea/lycoris/config.py) частей нетворка с возможными значениями: ```full, full-lin, attn-mlp, attn-only, unet-only, unet-transformer-only, unet-convblock-only```. А так же дополнительные параметры, по типу ```"use_cp=True"``` [для ускорения тренировки conv слоёв посредством потери точности](https://github.com/bmaltais/kohya_ss/blob/31b26d59d3988980e4ecab464ae19efca06b80dd/lora_gui.py#L1181) или специфичные для определённых алгоритмов параметры, как например для LoKR: ```"factor=4"```.

#### Lycoris
[Проект](https://github.com/KohakuBlueleaf/LyCORIS) одного неравнодушного анимешника для имплементации новых алгоритмов тренировки в сд-скриптс. Из этого проекта я могу выделить лишь один достойный внимания алгоритм.
##### LoCon
В дополнение к Attention слоям тренируемым классической Linear LoRA, этот алгоритм [тренирует Convolution слои блоков ResNet UNet'а](https://files.catbox.moe/7q4yn8.png).
- **conv_dim** - тоже самое, что и network_dim, только для этих слоёв. Размер этих слоёв складывается с размером network_dim в выходном файле. Хорошим значением будет **network_dim/2-4**, например при network_dim=64 это будет **32**.
- **conv_alpha** -  тоже самое, что и network_alpha, только для этих слоёв.

Эти слои можно накидывать в дополнение к любому другому алгоритму, или к обычной лоре. Подключение этих доп. слоёв очень благотворно влияет на тренировку стилей, чего нельзя сказать о персонажах, особенно с датасетом в одном стиле. Является ещё одним сильным бустером качества и замедлителем тренировки. Больше тренируемых компонентов вызывает снижение скорости тренировки, и точно также замедляет скорость генерации в инференс тайме при использовании такой лоры. Требует увеличения длительности тренировки, очень помогает избежать пережара, даже с неадекватными лр можно получить что-то приемлемое.

### --resolution ($resolution)
Разрешение тренировки. Самый главный повышатель качества тренировки. Каждые +64 пикселя дают огромный прирост мелких деталей и переносимость стиля. Повышать следует в первую очередь, учитывая свои возможности врам, потому что этот параметр по совместительству самый сильный замедлитель тренировки. Во-первых, большее разрешение снижает скорость итераций тренировки, во-вторых намного более слабое проявление результатов тренировки на одинаковых шагах. Примерные цифры при повышении с 512 до 768 это х2 шагов минимум, в третьих из-за большего потребления врам, позволяет использовать куда более меньший батч сайз, что в свою очередь ещё больше замедлит дело.

#### --train_batch_size ($train_batch_size)
Количество картинок из которых одновременно будет преобразовываться среднематематическое для обновления градиента и весов. Стоит ставить максимально возможное значение, позволяемое возможностями врам, так как каждый +1 существенно увеличивает её потребление. У карт с низким врам значения выше 1-2 недосягаемы, поэтому каждая картинка датасета будет влиять на результат сильнее, чем сразу несколько семплов, как в случае с 24гб картами, что не является чем то хорошим, но если датасет отполирован, то не страшно. Есть заблуждение, что этот параметр требует повышать лр для компенсации, но это не так. Достаточно лишь не ставить его большим, если датасет тоже является недостаточно большим и разнообразным, например бс5 и 15 картинок будет плохим выбором.

#### --gradient_accumulation_steps ($gradient_accumulation_steps)
Имитатор батч сайза для тех, у кого недостаточно VRAM для полноценного батч сайза. Объединяется с batch size подобным образом bs x ga. Общая формула для обновлений весов тем самым превращается в (количество пикч х повторы х эпохи) / bs x ga.

#### --gradient_checkpointing ($gradient_checkpointing)
Параметр для снижения потребляемой VRAM, посредством платы за это существенным замедлением тренировки.

### --noise_offset ($noise_offset)
Ужасная заплатка, с помощью которой можно решить [проблему дистрибуции шума, для генерации очень тёмных или очень светлых изображений за приемлемое количество шагов семплера](https://www.crosslabs.org/blog/diffusion-with-offset-noise). Ужасная она потому что при комбинации с ещё одной моделью/лорой натрененной таким способом картинка сгорит полностью, использовать эту одноразовую заплатку я крайне не рекомендую. [Слева](https://files.catbox.moe/l14is8.jpeg) можно наблюдать пример такого сожжения. Если данная перспектива не останавливает, хорошее значение в районе **0.05-0.1**.

#### --multires_noise_iterations и --multires_noise_discount
[Ещё одна](https://wandb.ai/johnowhitaker/multires_noise/reports/Multi-Resolution-Noise-for-Diffusion-Model-Training--VmlldzozNjYyOTU2) заплатка, призванная решить ту же проблему. Из того что я успел потестить, эта версия не имеет таких проблем с прожаркой, но и тренит стили как то хуже. Не могу сказать точно стоит ли это использовать, но я бы не стал.

### Tensorboard
Я очень много читал как умные и не совсем дядьки рассказывают про то, что в тензорборде должно всё быть как по учебнику с нисходящим Loss'ом. Это действительно так, но не в случае с кохьевсой дефолтной MSE (Mean squared error) функцией его подсчёта, по крайней мере для таких быстрых тренировок. Проблема в том, что она покажет лишь полный провал тренировки. Вот три скриншота с графиками: 

1. Normal train | 2. Boom shakalaka | 3. Overfit and underfit
------ | ------ | ------
[![Normal train](https://files.catbox.moe/3au4ak.png)](https://files.catbox.moe/3au4ak.png) | [![Boom shakalaka](https://files.catbox.moe/uemxbo.png)](https://files.catbox.moe/uemxbo.png) | [![Overfit and underfit](https://files.catbox.moe/ap5mwq.png)](https://files.catbox.moe/ap5mwq.png)

На первом абсолютно нормальная лора с хорошо получившейся стилизацией, *по учебнику* я должен был взять 18 эпоху, ведь там самое низкое значение потерь, но если взглянуть на общую картину, ни одна эпоха не превышает первую по значению, и можно спокойно выбрать любую. На втором намеренно выставленный х15 лр для демонстрации что действтительно покажет тензорборд, такого надо избегать, тренд в идеале должен быть или нисходящим, или хотя бы топчущимся на месте. На третьем скриншоте кстати те два нетворка из гридов про оверфит и андерфит повыше.
Если и это не остановило читающего этот гайд и он всё ещё хочет взглянуть в бездну, это можно сделать всё через тот же venv. Вне зависимости от установки найдите папку с сд-скриптс, откройте там повершелл и введите там команды:

```powershell
.\venv\Scripts\Activate.ps1
tensorboard --logdir="путь к папке с логами"
```
А дальше через браузер стоит проследовать по [этому адресу](http://localhost:6006/).

#### --logging_dir ($logging_dir)
Собственно папка в которую во время тренировки будут записываться логи для тензорборда.

#### --log_prefix ($log_prefix)
Префикс для логов. Полезно, если тренить много сеток. Можно задавать произвольно, например как в скрипте: ```$log_prefix = "$output_name" + "_"``` 

### Пути для файлов тренировки

#### --pretrained_model_name_or_path ($ckpt)
Путь к чекпоинту с которого будет происходить тренировка.

#### --output_dir ($output_dir)
Путь по которому будут сохраняться натрененные лоры.

#### --output_name ($output_name)
Имя сохранения файлов лор.

#### --train_data_dir ($image_dir)
Путь к датастеу.

#### --vae ($vae_path)
Путь к вае. Есть разные мнения использовать ли отдельное, не встроенное в модель вае во время тренировки или нет, я лично придерживаюсь того, что если и использовать то только вот [это](https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors), из моих тестов оно давало более лучшую детализацию, нежели то что по дефолту находится в NAI чекпоинте.

#### $sd_scripts_dir (только в скрипте)
Путь до установленных sd-scripts.

### --max_token_length ($max_token_length)
Максимальная длина для токенов в описаниях к пикчам. Достаточно просто сразу поставить 225 и не париться об этом параметре больше никогда.

#### --shuffle_caption ($shuffle_caption)
Перемешивание описаний к пикчам каждую эпоху, полезная штука, лучше тоже включать.

#### --keep_tokens ($keep_tokens)
Сохранять количество, указанное в этом параметре, **тегов** от перемешиваний. Это аргумент полезен лишь в случае, если вы хотите сохранить имя персонажа/название концепта и оно стоит на первом месте во всех описаниях к картинкам. Например, при тренировке персонажа, все картинки состоят из него и первым тегом идёт *shiina mayuri*. При тренировке стилей не имеет особого эффекта и лучше ставить 0, не выделяя отдельного тега и не сохраняя его.

#### --clip_skip ($clip_skip)
Собственно сам клип скип, работает по тому же принципу, как с простой генерацией, для аниме тренировок ставить значение 2, для реализма 1.

#### --seed ($seed)
Примерная аналогия с сидом, как и во время генераций, тоже нужно с чего то начать. Никак не влияет на тренировку, можно генерить автоматически каждый раз рандомный, или выбрать какой нибудь *lucky number* на удачу.

### --max_train_epochs ($max_train_epochs)
Количество эпох (повторений всего датасета) в течении которых будет трениться сеть.

#### --max_train_steps ($max_train_steps)
Количество шагов в течении которых будет трениться сеть. Выставлять нужно либо это, либо эпохи. Эпохи, тем не менее, всё равно будут сохраняться, после каждого полного прохода по датасету.
Рекомендации по предельному количеству итераций по картинкам **до деления** этого числа на batch size, с учетом всех включённых улучшателей тренировки и рекомендации по количеству картинок:
- От 8000 до 12000 для стилей. От 400 до 600 итераций на эпоху.
- От 2000 до 7000 для персонажей, в зависимости от сложности чара, грамотного подбора тегов и осведомленности модели о нём. От 300 до 500 итераций на эпоху.

#### --save_every_n_epochs ($save_every_n_epochs)
Как часто сохранять эпохи. Лучше поставить 1, чтобы сохранять каждую.

#### --save_last_n_epochs ($save_last_n_epochs)
Количество последних эпох, которые будут сохраняться. Чтобы вдруг ничего не удалилось лучше ставить значение больше, чем будет всего натренированных эпох.

### Дополнительные аргументы, которые стоит упомянуть

#### --cache_latents и --cache_latents_to_disk
Могут помочь сохранить ещё немножечко врам, особенно вначале тренировки. Но если кэшировать на диск, могут возникнуть разного рода конфликты в дальнейшем, поэтому если видите какие то странные ошибки тренировки, первым делом лучше будет вычистить эти .npz файлы из датасета.

#### --xformers
Ускоряет и сейвит врам также эффективно как и при генерации, стоит включать всегда.

#### --enable_bucket, --min_bucket_reso, --max_bucket_reso
Автоматический кроп под выбранное разрешение тренировки картинок и рассовывание их в "бакеты". Горизонтальные пойдут в 896х640 и схожие при выборе разрешения тренировки 768, вертикальные наоборот в 640х896 и схожие. Лучше ставить просто большой диапазон по типу ```--min_bucket_reso=256 --max_bucket_reso=1536```. Если в датасете будут преобладать, например вертикальные изображения, это может сказаться на итоговом качестве модели при генераций горизонтальных изображений.

#### --persistent_data_loader_workers
Выключает назойливые паузы меджу эпохами, стоит включать всегда.

#### --max_data_loader_n_workers
Я так и не встретил случая, где было необходимо значение больше двух, для ускорения работы. А вот повышение этого значения начинает отъедать львиную долю системной памяти (RAM). Не рекомендуется ставить значение больше 2.

***

## Решение проблем

Q: Ошибки, связанные с ```accelerate``` и ```default_config.yaml``` во время запуска ```install.bat``` скрипта.
-> ![](https://files.catbox.moe/fuaakf.png) <-
A: Поставить [vc_redist](https://aka.ms/vs/17/release/vc_redist.x64.exe) и запустить ```install.bat``` ещё раз.

Q: Ошибка связанная с ```zipfile``` во время запуска ```install.bat``` скрипта и ответа **y** на вопрос **Do you want to install the optional cudnn patch for faster training on high end 30X0 and 40X0 cards?**.
-> ![](https://files.catbox.moe/9wtzx7.png) <-
A: Это связано с недосягаемостью хоста с cudnn фиксом с вашего айпи. Решением будет рероутнуть траффик любым способом, например включить прокси/впн и запустить ```install.bat``` ещё раз.

Q: Какие-то проблемы с CUDA.
A: Вероятно не установлен [CUDA Toolkit](https://developer.nvidia.com/cuda-11-6-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11).

Q: У меня карточка 10-й серии и у меня вываливает ошибку при запуске тренировки. Что делать?
A: Скачать [альтернативные библиотеки cuda](https://github.com/james-things/bitsandbytes-prebuilt-all_arch), файл *libbitsandbytes_cudaall.dll* переименовать в *libbitsandbytes_cuda116.dll*, поместить по пути *sd-scripts\venv\Lib\site-packages\bitsandbytes\\* с заменой.

Q: У меня Windows 7 и PowerShell крашится.
A: Установите [PowerShell 6](https://github.com/PowerShell/PowerShell/releases/tag/v6.2.6).

Q: Сыпятся красные ошибки в консоли при выполнении скрипта!
A: Обновите [PowerShell](https://github.com/PowerShell/PowerShell/releases).

Q: Установил всё по гайду, но все равно не находит модули! Мне что, каждую зависимость устанавливать вручную?
A: Нет, процесс подготовки был отредактирован, а конкретно убран флаг *--system-site-packages*. Этот флаг отвечал за учёт системных библиотек, установленных по стандартному системному пути, и это нередко приводило к конфликтам (в т.ч. у автора). Удалите папку *venv* из *\sd-scripts* и пройдитесь по командам заново.

Q: При запуске тренировки через скрипт или anon1337-gui вылезает ошибка: **TypeError: ClusterConfig.__init__() got an unexpected keyword argument 'downcase_fp16'**
A: Ручная установка конфликтует с установкой derrian gui. Пофиксить можно через **accelerate config** зайдя в venv ручной установки sd-scripts.
