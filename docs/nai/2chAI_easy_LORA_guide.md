v0.1f
/ai/ Lora Complete Idiot Guide
-> ![](https://i.imgur.com/NmIIuXa.png) <-

[TOC]

#Lora Complete Idiot Guide
Ну что же, мой дорогой друг, познавая дивный мир нейрохудожеств ты захотел сгенерировать свою вайфу и удивился тому, что простой промт не может воспроизвести ее с должной точностью? Низкоранговая адаптация модели (LoRa) поможет тебе! Или, возможно, ты зашел сюда уже имея дела с лорами и решил сгенерировать свою?
Далее тебя ждет простой, но в то же время подробный гайд по их обучению на локальном компьютере. Для этого тебе потребуется видеокарта белого человека с 6 или более гигабайтами видеопамяти (для 1к серии есть нюансы с необходимостью альтернативных библиотек) и немного терпения.
!!! info
	Данный гайд рассчитан прежде всего для генерацию 2d тяночек на NAI-based моделях. Копродедам - увы, хотя основные положения могут быть справедливы
!!! danger
	Описанные действия предполагают актуальную(!) windows 10+, питон 3.10.x, наличие всех основных c++ redistributable, исправные драйвера nvidia и работающий без ошибок WebUi последней версии
!!! warning
	Обучающие программы при работе выделают себе большой объем оперативной памяти, а некоторую часть даже используют. Хорошая новость в том что все будет работать и на 16 гигабайтах, но потребуется выставить файл подкачки хотябы 32 гигабайта. Плохая в том, что в момент запуска и окончания обучения производительность компьютера будет отвратительной, желательно закрыть все программы, браузер и пойти попить чаю. На 32+гб ram идет гораздо комфортнее


Тренировка лоры будет описана на примере Shimakaze из лучшей гачадрочильни по корабликам
->![Shimakaze](https://imgur.com/mak1Lnd.png)<-
Скачиваем [**ДАТАСЕТ**](https://mega.nz/file/hORkXBLa#n9uoR88xhZ2ZTucd6PqQqo1XIb8OsYTlgec20Zu-wGs) (пароль стандартный) и распаковываем в папку без кириллицы и длинного пути.


#Установка и запуск
##Подготовка скрипта kohya-ss
В первую очередь нам потребуется стянуть [sd-scripts](https://github.com/kohya-ss/sd-scripts), который, собственно, и будет производить обучение. Гайд написан на версии 0.4.5, должен работать и на более новых.
Выбираем папку по душе, открываем в ней PowerShell (правая кнопка по пустому месту - открыть терминал), вводим в него:
***
```
git clone https://github.com/kohya-ss/sd-scripts --branch v0.4.5
```
***
!!! warning Пишет в ответ много красненьких букв среди которых имя "git" не распознано?
	Иди скачивай git для шиндоуз, как ты webui устанавливал?
Когда все скачалось забиваем следующие команды:
```
cd sd-scripts
python -m venv venv
.\venv\Scripts\activate
pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
pip install --upgrade -r requirements.txt
pip install -U -I --no-deps https://github.com/C43H66N12O12S2/stable-diffusion-webui/releases/download/f/xformers-0.0.14.dev0-cp310-cp310-win_amd64.whl

cp .\bitsandbytes_windows\*.dll .\venv\Lib\site-packages\bitsandbytes\
cp .\bitsandbytes_windows\cextension.py .\venv\Lib\site-packages\bitsandbytes\cextension.py
cp .\bitsandbytes_windows\main.py .\venv\Lib\site-packages\bitsandbytes\cuda_setup\main.py
```

***
Перед следующим шагом стоит сделать один необязательный, но крайне полезный шаг с обновлением библиотек. Скачиваем архив https://b1.thefileditch.ch/mwxKTEtelILoIbMbruuM.zip переходим по пути `.\venv\Lib\site-packages\torch\lib` и копируем 7 dll из архива туда с заменой.
***

- Продолжаем:
```
accelerate config
```
На все вопросы кроме Do you wish to use FP16 or BF16 (mixed precision)? просто нажимаем Enter, на него, используя стрелочки на намблоке с отключеным NumLock для перемещения, выбираем fp16 или bf16. Последний вариант более предпочтителен, но поддерживается только последними сериями видеокарт.

##Оснастка для запуска

Готово, теперь у нас есть машина для обучения, которой нужно скормить нужные параметры. Делать это можно разными способами, прямым вызовом accelerate с кучей параметров или использовать различные оснастки с более удобным представлением параметров.
Среди них есть:
- [ретард скрипт](https://raw.githubusercontent.com/anon-1337/LoRA-scripts/main/%D1%80%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B9/train_network.ps1) от одного из местных анонов
- [Гуи](https://github.com/anon-1337/LoRA-train-GUI/releases) от него же
- [Модный гуи-вебинтерфейс](https://github.com/bmaltais/kohya_ss)
- Прочие
!!! note В примере будет рассмотрен именно первый вариант
Причина проста - помимо довольно-таки удобного задания параметров и наличия базовых проверок без лишних свистоперделок, с ним любой хлебушек сможет устроить очередь на генерацию простым размножением скрипта и их поочередным запуском. Для утят что не могут без (не) красивых ползунков там, где они не нужны гуи версия будет позже (но это не точно).
~~Представляем лицо 16-гиговых неистово желающих иметь запущенным браузер при обучении~~

Ниже 2 примера с уже забитыми параметрами:
- [У меня 8 гигов или менее](https://mega.nz/file/cChjhDbJ#UP-rYgXFT68NHGZwJxXlnmvnD9xQPNSLpg7sqbhsEaU)
- [3090/4090 goes brrrr](https://mega.nz/file/ZfgQxYQA#hdEilI_-KUF1w1K0T93uXQAB0kRRqeeBVuf3-NWHvIg)

Открываем любым текстовым редактором, все что необходимо сделать - это изменить линии с 11 по 16 выставив пути к своему кохая-скрипту, модели, VAE, датасету и папке, куда будут сохраняться лоры. VAE подключать крайне рекомендуется чтобы не вылезали поломанные цвета и меньше ломало мелкие детали, выходную папку можно настроить сразу в WebUi чтобы лишний раз не копировать.
Какому датасету? Вот к [**ЭТОМУ**](https://mega.nz/file/hORkXBLa#n9uoR88xhZ2ZTucd6PqQqo1XIb8OsYTlgec20Zu-wGs), будь внимателен.
Какую модель указывать?
В зависимости от той модели StableDiffusion, на которой происходит тренировка, результат может меняться. Стоит выбирать или модель, которую вы используете наиболее часто и не содержащую избыточной стиллизации, или *ванильную NAI модель*. В данном гайде рассматривается именно второй вариант
!!! info	Если хочешь провести Шимка-тест
	воспроизводя результат из гайда - замени в скрипте значения параметроа `is_random_seed` `shuffle_caption` (строки 48-49) на 0, тогда у тебя будет использован тот же сид и отключено перемешивание токенов для снижения случайных факторов. При обычной тренировке `shuffle_caption` должен стоять единицей для получения наилучних результатов
	
***


Сохраняем, открываем терминал в папке со скриптом, вызываем его командой `./train_shim_brrr.ps1` (или другим именем скрипта)
!!! note Начало писать что-то на мунспике и появилисть прогрессбары
	Поздравляю, ты сделал все правильно
!!! warning Вылетает с ошибками
	обычно все необходимое для решения есть в ее описании, не ленись и прочти.
!!! info Если ругается на куду 
	Скачивай и ставь https://developer.nvidia.com/cuda-11-6-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11

Теперь под шум твоей высокотехнологичной печки стоит описать что мы вообще тут делаем. Если лень читать или хочешь сразу перейти к результатам - проматывай до раздела с использованием


#Подготовка датасета
Датасет есть необходимое (но не достаточное) условия для хорошей лоры. Мусор внутрь - мусор наружу, с другой стороны, если проебешься с параметрами обучения то и из конфетки можно сделать говно.
##Граббер
Как собирать? Если желаемый персонаж относительно известный (или на целевой стиль есть хотябы пара десятков пикч) то помогут нам наши невольные друзья-художники, буры и софт для массового скачивания с них.
Качаем и ставим https://github.com/Bionus/imgbrd-grabber 
!!! note настраиваешь проксю или подключаем впн если живешь в этой стране

Запускаем, жмем ctrl+T, внизу нажимаем кропку «источники» и выбираем gelbooru (наиболее безпроблемный с отсутствием ограничений на число тегов поиска) или сразу несколько желаемых.
Слева внизу выбираем папку куда все будет сохраняться, в поле **имя** вставляем `%position%.%ext%`, сохраняем.
-> ![Путь сохранения](https://imgur.com/GUsG6k3.png) <-

Теперь идем в настройки-сохранить-Отдельные файлы журнала, жмем кнопку добавить, указываем ту же папку, имя файла `%position%.txt`, содержимое ```%all:unsafe,separator=^,^ %```
-> ![Текстовые файлы с тегами](https://imgur.com/ErehXat.png) <-
***
Возвращаемся обратно в новое окно, в поле тегов вбиваем желаемое, используя -исключаем то что не хотим, также полезным будет сделать сортировку по оценкам добавив ```order:score```
-> ![Поиск](https://imgur.com/XIaksw4.png) <-
Когда теги устраивают - нажимаем **скачать все**, переходим на вкладку **Загрузки** и из контекстного меню к только что созданной задаче на скачивание выбираем загрузить.
##Сортировка пикч с бур
Скачанные пикчи крайне желательно отсортировать, выбрав наилучшие и удалив хуевые. Хорошо подходят для обучения чистые картинки где изображен только желаемый персонаж в адекватной позе, без гротескного стиля, комиксов, сложных взаимодействий, других персонажей и прочего.
!!! note Пример подходящих пикч
->![Подходящие](https://imgur.com/cRjQ5df.jpg)<-
!!! danger Пример неподходящих пикч
->![Неподходящие](https://imgur.com/aLkiGv0.jpg)<-
***
Основную часть неудачных, разумеется, следует отсекать негативными тегами при поиске.
!!! info Что касается сфв/левд 
	В целом разницы нет, за исключением того, что при малое число пикч с уникальным костюмом на фоне его отсутствия приведет к худшему его воспроизведению, а за слишком целомудренными датасетами замечена генерация нсфв без запроса и даже сквозь негативы.
Также крайне проблемными будут элементы интерфейса, подписи, баблы диалогов и прочие вещи что можно встретить.
Если их будет много, то оно начнет лезть на каждую генерируемую пикчу и избавиться будет сложно. Поэтому открываем любой редактор и простой кистью с цветом фона (или восстанавливающей кистью в фотошопе) стараемся их замазать.
***
->![Подписи](https://imgur.com/PZ9w4fM.jpg)<-
!!! note 
	Если этого много а пикча хороша - кропаем отсекая ненужное. То же стоит делать если целевой персонаж находится уж очень далеко. Пикчи с соотношением сторон выходящим за 3к1 также кропаем.
->![Кроп](https://imgur.com/Mxfjp74.jpg)<-

Фанатизма здесь не нужно, достаточно убрать только самые крупные огрехи.
!!!warning Последней проблемой на пути может стать прозрачный фон
Просто заливаем его белым цветом и тут же в текстовом файле с тегами меняем transparent background на white background, simple background, или дропаем эту пикчу.
***
Что касается размера датасета здесь ==**качество>>>>>>количество**==, для тренировки лоры на персонажа хватит и 30 пикч если они разнообразны. 
!!! info *Оптимальным* по количеству можно назвать диапазон от 50 до 300
Главное - стремиться к относительному разнообразию в ракурсах, одежде (ее отсутствие считается), фонам. Если последние будут монотонными и однообразными или что еще хуже одноцветной заливкой, то это может вызвать дальнейшие проблемы с фонами на генерациях. Что касается стиля - если большая часть пикч в одной стилистике то она будет усвоена и воспроизведена. При не идеальных настройках обучения или скудном датасете это также приведет и к влиянию на фон, хорошо это или плохо - зависит от цели.
Кропать пикчи до квадратов или снижать их разрешение до 512 не нужно - скрипт сделает это сам используя несколько соотношений сторон.

##Теггирование датасета

Разобравшись с пикчами теперь можно перейти к фиксам тегов, вещь опциональная но послушность улучшает. Манипуляции проводятся со всеми текстовыми файлами, что нам создал граббер в ходе скачивания. Делать можно с помощью нормального текстового редактора (например, notepad++) используя замену во всех файлах, простым скриптом на известном вам языке или любым желаемым способом.
***
Прежде всего необходимо удалить мусорные теги буры, которые будут  тратить токены клипа и сбивать с толку сеть:
```
absurdres
highres
commentary request
commentary
artist name
commission
...
```
Также, во многих случаях имеет смысл удалить коллосальных размеров теги, присущие персонажам из игр, описывающие названия их альтернативных костюмов. В случае Шимки это
```
shimakaze (the white rabbit of wonderland) (azur lane)
shimakaze (world's speediest bunny waitress) (azur lane)
...
```

Далее, желательно поставить тег персонажа на первое место чтобы он всегда на нем оставался при их перемешивании и в случае если они не влезают в указанное число токенов, также длинный тег можно сократить для уменьшения занимаемых токенов как при обучении, так и при дальнейшем вызове.
!!! info Если источник пикч датасета – не граббер, что любезно создает готовые файлы с тегами – придется использовать различные оснастки для автотегинга (WD1.4 tagger, DeepDanbooru), или ебошить вручную.

##Структура папок

Когда пикчи и теги к ним у нас готовы – нужно раскидать их по папкам. Для этого в первую очередь ==считаем количество пар пикча-теги, выбираем число шагов обучения (для начала стоит взять 4000 чтобы с запасом), делим это число на 10 (число эпох в нашем обучении), делим на количество и получаем необходимое число повторений каждой пикчи==.
Округляем в большую сторону, создаем папку с именем N_a где N - найденное число и перемещаем в нее все пикчи и текстовые файлы с тегами.
!!! info Пример
	В датасете из начала гайда 61 пикча, предполагается что целевой свитспот лежит в диапазоне 2300-3000, использовано 6 повторений что должно дать хороший результат на 6-8й эпохе.
***
Логика структуры папок датасета довольно таки простая – цифры в начале означают количество повторений при обучении, a – любое имя. Использовать это можно если в датасете есть небольшое количество хороших-годных пикч и много хуевых. В таком случае разумным будет положить хорошие в свою директорию присвоив ей больше повторений, а остальное в другую с меньшим.

#Параметры обучения
Теперь переходим к самому веселому и спорному - параметры обучения.
!!! warning Если ты гуманитарий
	то предварительно загляни [сюда](https://ru.wikipedia.org/wiki/%D0%AD%D0%BA%D1%81%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%B7%D0%B0%D0%BF%D0%B8%D1%81%D1%8C)
***
Для начала разберем краткий перечень основных параметров:
- ==Число шагов==
описано выше, определяется как `число пикч*число их повторений*число эпох`. Если их слишком мало - модель не успеет обучиться, если слишком много - будет переобучение, выражающееся в общем распидорашивании, ухудшении обработки тегов, взрывах фона, появлению не удаляемых элементов одежды. В случае невысокого лр может было малозаметно, но проявиться потом рандомно в мелких элементах.
->Недотрен-оптимум-перетрен<-
->![Пример](https://imgur.com/7YitEFf.jpg)<-

- ==network_dim== 
ранг сети, напрямую влияет на ее размер и количество деталей которое она в теории может вместить. На практике больше 32 разница уже не заметна, но больше не меньше, так что можешь смело оставлять 128

- ==network_alpha==
хочешь стабильно работающую модель оставляй единицей, хочешь поломанную, но (изредка) дающую интересный результат - ставь равной network_dim, возможны промежуточные значения. Ходят слухи что второй вариант наиболее предпочтителен для обучения на стиль, но объективных данных мало. Также автор может подтвердить возможность крайне крутых результатов с поломанными моделями, вот только их доля мала а большая часть пикч будет захуевлена в высокой вероятностью. Большое поле для экспериментов, на свой страх и риск.

- ==train_batch_size==
количество потоков параллельной тренировки, каждый поток отъедает свою врам. В теории большее число потоков дает более качественное обучение, на практике это не заметно, возможно из-за рандома и сложностей объективного отслеживания. Хочешь исследовать - велкам. Из некоторых экспериментов таки стало ясно что большой батч сайз прощает ошибки настроек, чрезмерный лр проявится не так ужасно, слишком долгая тренировка упорет модель меньше, вот наглядный пример
![Пример BS](https://files.catbox.moe/flm65r.jpg)
Обе модели перетренены и имеют проблемы с фоном и управляемостью, но та что на низком BS совсем приуныла. При этом на ранних эпохах они схожи и не показывают разницы в темпе обучения.
!!! info Главный факт в том что  повышение BatchSize снижает время, затрачиваемое на обучение
	за счет более эффективного использования ресурсов gpu. Так что ставь сколько влезает в врам


- ==scheduler==
планировщик обучения, который будет менять множитель ее скорости в ходе прогресса. Вариантов много, стоит попробовать все, кроме, разве что, постоянного. Косинус дает неплохие результаты.

- ==unet_lr==
скорость обучения модели денойзинга, определяет то насколько интенсивно обучатель будет шатать параметры модели, пытаясь натянуть ее на твою пикчу
- ==text_encoder_lr==
то же самое но для текстовой модели. Рекомендуется выставлять в диапазоне от половины unet_lr до равной ей/
Оба пераметра сильно зависят от соотношения alpha и network_dim, также в теории должна быть зависимость от train_batch_size. При низком значении модель не сможет нормально обучиться сколько не трень, при слишком высоком все распидарасит.
!!! note Пример грида с различными LR (alpha=1, LR в имени модели, dim=128, BS=12)
[![Пример LR](https://imgur.com/JHB18Ga.jpg)](https://imgur.com/JHB18Ga.jpg)
!!! note Пример слишком низкого LR с разбиением по эпохам
[![Низкий LR](https://imgur.com/PKo34JV.jpg)](https://imgur.com/PKo34JV.jpg)
!!! note Пример слишком высокого LR с разбиением по эпохам
[![Высокий LR](https://imgur.com/SttUznc.jpg)](https://imgur.com/SttUznc.jpg)
***
Автор настоятельно рекомендует попробовать сравнительно высокие значения LR (2e-3) и его окрестности с планировщиком косинус, alpha=1, dim=64..128 и числом шагов ~2500. Есть мнение что долгие обучения на низких лр позволяют получить наилучший результат а подобный подход хуев - пруфов этого мы так и не увидели, есть лишь обратное, однако ты, анон, можешь взять и сам сравнить.

- ==Число эпох== 
в начале каждой эпохи пикчи загружаются в память, проходит перемешивание тегов (если включено) и обучение продолжается с прошлой точки. Как правило промежуточные состояния лоры сохраняются каждую эпоху, соответственно если целевое число шагов обучения хотя бы примерно известно, то нет смысла ставить их более 10 штук, ибо разница между соседними будет малозаметна. Есть мнение что большее число эпох позволяет получить некоторые преимущества (при этом возможно настроить сохранение модели раз в N эпох, а не на каждую), однако есть и негативные эффекты и ничего из этого не было как-то запруфано, поэтому ориентироваться стоит прежде всего на число шагов, а на эпохи. Если видишь в треде кто-то обучает с десятками-сотнями эпох на аниме персонажа - смело кидай в него камень, может родит пруфы и таки внесет революцию.

- ==save_precision, mixed_precision==
Выбирай или fp16 или bf16. Последний формат предпочтителен так как покрывает больший диапазон значений (пусть и с меньшей точностью но это не так важно), но работает только на последних видеокартах.

!!! info Менее важные параметры
Разрешение тренировки - для sd1.x моделей, коими являются почти все анимублядские оставляй 512 и не трогай
clip_skip = 2 аналогично прошлому
max_token_length - число обрабатываемых токенов, подбирается по наиболее длинному набору тегов из пикч, просто скопируй его в промт webui и посмотри на счетчик справа. Меньше - лучше (в теории), небольшая обрезка при их превышении не создаст проблем
keep_tokens - число тегов (не токенов как в названии!), которые будут оставаться на первом месте при их перемешивании, именно для этого мы стремились ставить тег персонажа в самое начало
shuffle_caption - признак перемешивания тегов, должно быть включено

Остальные параметры на данный момент нас не интересуют, внимания достойны разве что оптимизаторы но они уже выходят за рамки гайда для неофитов.

#Использование и тестирование лоры
##Вызов лор
!!! note Вызвать лору можно двумя способами: 
- через промт штатными средствами sd-webui (кнопка show extra networks под Generate и вкладка Lora) откроет их список и по клику вставит в промт конструкцию типа <lora:NAME:1> где 1 - ее вес
- через [аддон](https://github.com/kohya-ss/sd-webui-additional-networks)

Первый способ проще, второй удобнее и функциональнее, стоит отметить что на одних сидах они дают разные результаты.
!!!info
	В случае аддона рекомендуется зайти в настройки webui, найти в поиске =="Extra paths to scan for LoRA models"== и прописать в ней `%путь_до_сд%\stable-diffusion-webui\models\Lora` чтобы использовать стандартную папку с лора-моделями, куда они должны быть скопирвоаны.
***
Для начала выбираем последнюю эпоху сгенерированной выше лоры, выставляем вес 0.8, выбираем модель anything-v4.5, выставляем следующие параметры генерации
***
![Imgur](https://imgur.com/eqLihdw.png)
![Imgur](https://imgur.com/5RTgCxg.png)
***
Вбиваем промт:
```
best quality, masterpiece, ultra-detailed, shim, 1girl, animal ears, armpits, azur lane, black footwear, black gloves, black hairband, black skirt, blush, brown thighhighs, cake, clothes lift, cup, female focus, food, frilled hairband, full body, gloves, standing, long hair, looking at viewer, panties, rabbit ears, shoes, skirt lift, solo, [white|blue] striped panties, thick eyebrows, thighhighs, underwear, white hair, yellow eyes
Negative prompt: (worst quality, low quality:1.4), multiple views
```
и неистово генерируем!
***
!!! note Если все выполнено правильно то встретить нас должно что-то на подобии пикрелейдет
[![Шимка](https://imgur.com/iWtqB6x.png)](https://imgur.com/iWtqB6x.png)
***
Конкретный результат может несколько отличаться из-за разных сидов обучения
***
!!! danger Если же вы видите следующий пик
![Отсутствие лоры](https://imgur.com/IEmUbyX.png)
значит что-то пошло не так и лора вообще не применилась, нужно нажать налочку ==**Enable**== или поискать ошибки в консоли.
***
!!! info Шимка-тест
Если в прошлой генерации персонаж воспроизводится и в настройках обучения был выбран статичный сид и отключено перемешивание токенов - вбиваем в поле `Seed` значение `13371488`, еще раз проверияем соответствие настроек скрину выше и генерируем. Должна получиться одна из референсных пикч:
***
[![BS12](https://imgur.com/Sh10eFg.png)](https://imgur.com/Sh10eFg.png) [![BS2](https://imgur.com/5B6CJvH.png)](https://imgur.com/5B6CJvH.png)
***
Небольшие отличия возможны, поскольку как при обучении, так и при генерации используется xformers.
***

##Использование гридов

Для тестирования и сравнения лор, а также поиска свитспота рекомендуется использовать гриды.
!!! info Есть мнение что они вообще нихуя не характеризуют и не нужны
	Разумеется это ~~шиза~~ ерунда, однако есть в этом утверждении разумное зерно - может попасться оче хуевый или наоборот хороший сид в котором реальные недостатки не проявятся а косяки исходной модели SD будут приняты за проблемы с лорой. Поэтому делаем всегда несколько штук с разными промтами и/или заказываем несколько генераций сразу.
После задания промта и параметров, включем аддон, выбираем (любую) модель и мотаем в самый низ в скриптах выставляя X/Y/Z plot. По одной из осей выставляем AddNet Model и в строке через запятую перечисляем нужные модели, по другой AddNet Wight и выставляем интервал весов, запускаем генерацию.
***
![Imgur](https://imgur.com/MqDVXRx.png)
***
!!! note В случае ошибки при задании параметров генерация не запустится
	ищите ошибке в консоле

[![Грид](https://imgur.com/cTOakvN.jpg)](https://imgur.com/cTOakvN.jpg)
***
Влияние веса и эпохи представлено довольно таки наглядно. Стоит отметить что ==нормальная лора должна хорошо срабатывать с весом вплоть до 0.9 ничего не ломая==.
Исключения допустимы, особенно если результат нравится, но то что они поломаны или перетренены - факт.

##Качество лор
Если почитать различные ресурсы, где обсуждаются аи-генерации, можно встретить смехуечки и общие слова о низком качестве большей части лор, что выкладывают пользователи на популярных ресурках, наподобии https://civitai.com/. Или, возможно, вы и сами замечали что при применении некоторых из них куда-то уплывает стиль, ломается фон, глаза и лица первращаются в кашу, вместо задуманного промтом генерируется непонятно что. Разумеется, причиной этого является сама используемая лора, а вызвано это может быть плохим датасетом, неподходящими настройками обучения или несовместимостью с используемой моделью SD.
Также, проблемы могут проявиться, например, при одновременном использовании нескольких лор, или же в том, что отдельные детали персонажа воспроизводятся не так как хотелось бы. Например, если внимательно поиграться с лорой Шимки из гайда, то можно заметить проскакивающие ошибки с ее бровями (другой цвет, форма, дублирование) и воспроизведение прекрасного андербуба на оригинальном костюме лишь в ~30% случаев. Повесть о том как решать эти проблемы, а также некий разбор параметров обучения с большим числом примеров не только на персонажа будет позже, при удачном стечении обстоятельств. Поучаствовать в обсуждении того что туда попадет ты можешь уже сейчас, заглянув в технотред.

За сим все, вопросы задавай в тред. По успеху не забудь запостить свои мастерписи в nai-тред, параллельно вознося почести местным кемономими-богиням.