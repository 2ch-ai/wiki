---
title: 2ch /nai/ вики
---

<style>
  h1 {
    display: none;
  }
  .md-content__button {
    display: none;
  }
</style>

<center>
  <img style="pointer-events: none; height: 150px;" src="https://counter.seku.su/cmoe?name=2ch_nai_wiki&theme=gb" />

  <div style="font-size: 22px; font-weight: bold; font-family: monospace;">
    Добро пожаловать на 2ch /nai/ вики!
  </div>
</center>

Здесь ты найдёшь всю необходимую информацию, чтобы начать генерировать аниме-тяночек, используя новейшие разработки в нейросетевых технологиях. Используй навигатор на левой панели, чтобы найти нужную тебе информацию.

~~Данная вики ведётся анонимными специалистами по машинному обучению мирового уровня и активно дополняется.~~

**FAQ**

#### Я здесь в первый раз, с чего мне начать?  
Абсолютный минимум для вката - это установить [пользователький интерфейс](./interfaces.md) для работы с нейронками и скачать любую понравившуюся [модель](./models/index.md).  

??? note "Краткое руководство по вкату (NVidia)"
    * Скачай [последний релиз интерфейса Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/tag/latest)
    * Зарегистрируйся на <https://civitai.com> после чего скачай модель [AutismMix](https://civitai.com/models/288584?modelVersionId=324619) (либо же любую другую на выбор) и забрось её в `/models/Stable-diffusion`
    * Запусти update.bat и дождись завершения операции  
    * Запусти run.bat и дождись, пока подтянутся все зависимости и откроется веб интерфейс по адресу <http://127.0.0.1:7860>  

    Для начала можешь использовать такие настройки генерации (пример для AutismMix):

    * **Sampling method**: Euler a
    * **Schedule type**: Automatic
    * **Sampling steps**: 25
    * **CFG Scale**: 7
    * **Разрешение изображения**: 1280 x 1080 - можешь экспериментировать с соотношением сторон, но не выставляй разрешение сильно выше. Для получения более крупных картинок используй техники [апскейла](./upscale.md), такие как Hires. fix

    * Начинай свой **промпт** с перечисления тегов качества, дальше дополняй [буру-тегами](./prompts.md#где-брать-теги) с перечислением того, что хочешь видеть:
    ```
    score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, source_anime
    ```

    * **Негативный промпт**:
    ```
    source_furry, source_pony, source_cartoon, yellow background, 3d, muscular, thick thighs
    ```

    Примеры промтов можно посмотреть на civitai в описании к картинкам.

    Модель знает часть старых персонажей. Если кто-то не получается, то нужно скачать/обучить [LoRA-модель](./lora/index.md) на этого персонажа. Так же существуют множество LoRA-моделей на стили разных художников.

Если предпочитаешь более подробные руководства, то можешь ознакомиться с гайдами в зависимости от твоей видеокарты: [NVidia](https://rentry.co/2ch_nai_guide) или [AMD](./install/amd.md).

Если же у тебя всё плохо с железом, то можешь воспользоваться [облачными вариантами](./install/clouds.md) генерации.

---

#### Какие системные требования для запуска этих нейронок?
В первую очередь, всё зависит от количества видеопамяти (VRAM) на твоей машине. Разные чекпоинты (модели) требуют разное количество видеопамяти.

Таблица актуальна для NVidia:

| Базовая модель      | Минимальный объём VRAM | Рекомендуемый объём VRAM |
| ------------------- | ---------------------- | ------------------------ |
| Stable Diffusion 1  | 4 GB VRAM              | 8 GB VRAM                |
| Stable Diffusion XL | 8 GB VRAM              | 12 GB VRAM               |
| FLUX                | 12 GB VRAM             | 24 GB VRAM               |

Потребуется около 10-20 GB свободного места на жёстком диске, чтобы установить все необходимые для запуска нейронок интерфейсы и библиотеки.

Кроме этого, тебе нужно будет скачать, как минимум, один чекпоинт, который ты будешь запускать:

| Базовая модель      | Требуемый объём на жёстком диске                                              |
| ------------------- | ----------------------------------------------------------------------------- |
| Stable Diffusion 1  | от 2 GB  до 4 GB                                                              |
| Stable Diffusion XL | 6.5 GB                                                                        |
| FLUX                | от 4 GB до 24 GB на основную модель + от 2.5 GB до 19 GB на текстовый энкодер |

Рекомендуется размещать все связанные с нейронками файлы на SSD. Впрочем, это повлияет только на скорость загрузки интерфейсов и моделей - на скорость генерации это не влияет.

---

#### Что насчёт цензуры?
Наиболее популярные локальные модели не имеют какой-либо цензуры. Однако, модель можеть не знать какие-то концепты/фетиши, что, впрочем, исправляется при помощи такого механизма, как [LoRA](./lora/index.md).

Для NSFW рекомендуется использовать модели на основе [Pony Diffusion V6 XL](./models/pony-diffusion-v6-xl.md). В случае, если доступный тебе объём видеопамяти не позволяет запускать XL-чекпонты, рекомендуется обратить внимание на [EasyFluff + HLL](./models/easy-fluff.md). 

В онлайн-сервисах по типу [civitai.com](https://civitai.com) существует цензура, блокирующая определённые запросы. Со списом запрещённых на CivitAI слов можешь ознакомиться [здесь](https://github.com/civitai/civitai/blob/main/src/utils/metadata/lists/blocklist.json) и [здесь](https://github.com/civitai/civitai/blob/main/src/utils/metadata/lists/blocklist-nsfw.json).

---


#### Какой интерфейс выбрать начинающему?  
[Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge) - наиболее передовой из user-friendly интерфейсов в сфере картинко-генераций. Рекомендуется начать с него.

---

#### Где искать модели?  
[civitai.com](https://civitai.com/) - самый крупный ресурс, хранящий модели, лоры и всё прочее. Фактически, это основной поисковик в сфере картинко-генераций. 

---

#### Какую модель выбрать начинающему?  
[AutismMix](https://civitai.com/models/288584/autismmix-sdxl) - один из самых популярных мёрджей модели PonyDiffusion V6 XL.

Данная модель предоставляет хороший базовый стиль и анатомию, но ценой является снижение вариативности генераций. Хороший вариант для начинающего.

---

#### Нейронки знают персонажа %waifuname%?  
Зависит от того, насколько твоя вайфу популярна - Хатсуне Мику или Аску Лэнгли знает любая уважающая себя аниме модель. Но вон ту няшу из текущего онгоинга, вероятно, ни одна из моделей не знает.

Впрочем, не стоит отчаиваться, ведь существует такой механизм как [LoRA](./lora/index.md), который позволит тебе сгенерировать нужного персонажа, даже если основная модель о нём не знает.

---

#### Что такое **LoRA**?  
Метод дообучения нейросетевых моделей, главной особенностью которого является то, что он не вносит изменения в обучаемую модель. Вместо этого создаётся небольшой файл, содержащий патч с изменениями.

Подробнее смотри в [этой статье](./lora/index.md).

---

#### Что такое **ControlNet**?  
Cпособ управления процессом генерации изображения с помощью дополнительных нейросетей. Ты можешь задавать дополнительные условия, например, контуры, глубину или позу человека, чтобы получить более точный и желаемый результат.

Подробнее смотри в [этой статье](./controlnet/index.md).

---

#### Как активировать тёмный интерфейс?
Добавь `--theme dark` в параметрах запуска батника.

---

#### Как мне поставить генерацию картинок на ночь?

??? note "Правая кнопка мыши на кнопку "Generate" -> "Generate forever"."
    ![](https://files.catbox.moe/uc48c7.webp)

---

#### Как восстановить последние использованные настройки после перезапуска интерфейса?
??? note "Вариант 1: Используй синюю кнопку со стрелкой, которая находится под кнопкой генерации"
    ![](https://files.catbox.moe/7llnrl.webp)

??? note "Вариант 2: Используй плагин stable-diffusion-webui-state"
    Поставь [плагин](https://github.com/ilian6806/stable-diffusion-webui-state), перезапусти автоматик, перейди в Settings -> State и там выбери, какие из настроек ты хочешь сохранять после перезапуска.

    ![](https://files.catbox.moe/pn6iek.webp)

!!! note "Вариант 3: Используй плагин [Config-Presets](https://github.com/Zyin055/Config-Presets)"

---

#### Как мне вынести настройки VAE и Clip-skip в верхнюю часть интерфейса?
Открой "Settings -> User interface" и выстави в поле "Quicksettings list" следующую строку:

```
sd_model_checkpoint,sd_vae,CLIP_stop_at_last_layers
```

??? note "Картинка с инструкцией"
    ![](https://files.catbox.moe/hy25fk.webp)



---

#### Как вы создаёте эти огромные 4k/8k картинки?
При помощи различных техник апскейла, таких как тайловый апскейл с помощью скрипта SD Upscale или плагина [multidiffusion-upscaler-for-automatic1111](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111).

Подробнее смотри в [этой статье](./upscale.md).

---

#### Генерируются чёрные квадраты
У тебя проблема с VAE, смотри решение [здесь](./vae.md#перестаём-генерировать-чёрные-квадраты).

---

#### Почему у персонажа неправильное количество пальцев?
Это общая проблема всех диффузионных моделей. Либо используй читы в виде какого-нибудь из тегов рода:

* `arms behind head`
* `arms behind back`
* `arms between legs`
* `arms in pockets`

Либо придётся исправлять кривые пальцы после генерации через Inpaint.

----

#### Почему персонаж генерируется несколько раз на одной картинке?
1. Используй позитивные теги `1girl, solo` и негативные `2girls, multiple characters`
1. Уменьши стартовый размер картинки и увеличивай её при помощи алгоритма Hires. fix
2. Если ты уже используешь Hires. fix, то уменьши denoising strength

---

Ты дочитал FAQ до конца. Молодец!

Если у тебя остались ещё вопросы, спрашивай в [Anime Diffusion](https://2ch.hk/ai/) треде.